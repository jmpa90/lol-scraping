name: Test Scraper (Optimized)

on:
  workflow_dispatch:

jobs:
  test-print:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          path: scraper_repo

      - name: Checkout Data
        uses: actions/checkout@v4
        with:
          repository: jmpa90/lol-replays-downloader
          token: ${{ secrets.DATA_REPO_TOKEN }}
          path: data_repo
          sparse-checkout: |
            data/players.csv

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # ========================================================
      # 1. CACHING DE PIP (Librer√≠as Python)
      # ========================================================
      - name: Cache Python packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('scraper_repo/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # ========================================================
      # 2. CACHING DE PLAYWRIGHT (Navegadores)
      # Esto evita bajar Chromium cada vez.
      # ========================================================
      - name: Cache Playwright Browsers
        id: cache-playwright
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-v1.57.0 # Cambia la version si actualizas requirements

      - name: Install Dependencies
        working-directory: ./scraper_repo
        run: |
          pip install pandas playwright
          
      - name: Install Playwright (If not cached)
        working-directory: ./scraper_repo
        # Solo corremos esto si NO hubo cache hit
        if: steps.cache-playwright.outputs.cache-hit != 'true'
        run: |
          playwright install chromium
          playwright install-deps

      - name: Run Scraper Test
        working-directory: ./scraper_repo
        run: python scripts/opgg_get_match_url.py

      # ========================================================
      # 3. SUBIR ARTEFACTOS (Las Fotos)
      # Esto sube cualquier .png generado para que lo descargues
      # "always()" asegura que corra aunque el script falle.
      # ========================================================
      - name: Upload Debug Screenshots
        if: always() 
        uses: actions/upload-artifact@v4
        with:
          name: debug-screenshots
          path: scraper_repo/*.png
          retention-days: 5