name: Daily OP.GG Scrape (Print Only)

on:
  schedule:
    - cron: '0 9 * * *'
  workflow_dispatch:

# Ya no necesitamos permisos de escritura (contents: write) porque no guardamos nada
permissions:
  contents: read

jobs:
  scrape-job:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Scraper Code
        uses: actions/checkout@v4
        with:
          path: scraper_repo

      - name: Checkout Data Repo
        uses: actions/checkout@v4
        with:
          repository: jmpa90/lol-replays-downloader
          token: ${{ secrets.DATA_REPO_TOKEN }}
          path: data_repo
          sparse-checkout: |
            data/players.csv

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache Python packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('scraper_repo/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Cache Playwright Browsers
        id: cache-playwright
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-v1.57.0

      - name: Install Dependencies
        working-directory: ./scraper_repo
        run: |
          pip install pandas playwright
          
      - name: Install Playwright (If not cached)
        working-directory: ./scraper_repo
        if: steps.cache-playwright.outputs.cache-hit != 'true'
        run: |
          playwright install chromium
          playwright install-deps

      - name: Run Scraper (Print Only)
        working-directory: ./scraper_repo
        run: python scripts/opgg_get_match_url.py

      # Subimos logs visuales solo si falla, por seguridad
      - name: Upload Debug Artifacts
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: debug-screenshots
          path: scraper_repo/*.png
          retention-days: 1